
## Yelp Data Storage

Each file is composed of a single object type with one JSON object per line. A relational table might seem an excellent choice to store the data, but there are fields from business listings data that exhibit multiple values (attributes and categories), and it would be hard to find or show if they are all stored in the same column. It is why the Yelp data team provided the data in JSON format, stored as documents, as JSON documents support embedded fields, so data and lists of data associated with the instance of record can be stored with the document. Considering the structure of the data files provided, MongoDB is suitable to store the data of this nature as the data are in embedded document structure. MongoDB is document-oriented, providing high performance without needing to fix any schema on the data that can be used to store any data.

The relational database is not suitable as it is developed to handle data in tabular format, and it is not suitable to handle JSON files unless we convert it to structured tabular format as suggested by the GitHub repository  to convert the JSON data to CSV to get the nested value from the JSON structure. However, due to the massive volume of data and variety of data types (structured, semi-structured, and unstructured), the relational database is unsuitable as it is not scalable and only handles structured data. Data retrieval is also slower as the information is stored in different tables compared to the NoSQL database. HBase is also not suitable in this case as it is column-oriented for storing structured data, not data in JSON files. It also does not have the feature of searching document data. MongoDB has a feature using find to facilitate the searching process, as the attribute can be indexed. HBase is unable to perform complex data queries and analyses.

However, storing data in JSON will require reading each record from the document and parsing it for the data whenever it is performed. It will result in much more disk and memory. Besides, complex data queries and data cleaning are not easy to be performed using MongoDB as lengthy scripting is required. Thus, MongoDB is only suitable for storage and simple data querying. For further pre-processing, other Hadoop tools should be used instead. HDFS is another alternative storage for these JSON files when pre-processing is required using other tools. First, the JSON data are loaded to HDFS storage. Then using Hadoop tools such as Apache Spark, Hive, and Pig, the JSON files can be loaded to the environment for further transformation as these tools have the built-in function to handle and read the JSON files. Both storage methods using MongoDB and HDFS will be discussed for demonstration.
