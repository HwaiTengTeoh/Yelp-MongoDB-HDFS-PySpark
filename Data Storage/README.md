
## Yelp Data Storage

Each file is composed of a single object type with one JSON object per line. A relational table might seem an excellent choice to store the data, but there are fields from business listings data that exhibit multiple values (attributes and categories), and it would be hard to find or show if they are all stored in the same column. It is why the Yelp data team provided the data in JSON format, stored as documents, as JSON documents support embedded fields, so data and lists of data associated with the instance of record can be stored with the document. Considering the structure of the data files provided, MongoDB is suitable to store the data of this nature as the data are in embedded document structure. MongoDB is document-oriented, providing high performance without needing to fix any schema on the data that can be used to store any data.

The relational database is not suitable as it is developed to handle data in tabular format, and it is not suitable to handle JSON files unless we convert it to structured tabular format as suggested by the GitHub repository  to convert the JSON data to CSV to get the nested value from the JSON structure. However, due to the massive volume of data and variety of data types (structured, semi-structured, and unstructured), the relational database is unsuitable as it is not scalable and only handles structured data. Data retrieval is also slower as the information is stored in different tables compared to the NoSQL database. HBase is also not suitable in this case as it is column-oriented for storing structured data, not data in JSON files. It also does not have the feature of searching document data. MongoDB has a feature using find to facilitate the searching process, as the attribute can be indexed. HBase is unable to perform complex data queries and analyses.

However, storing data in JSON will require reading each record from the document and parsing it for the data whenever it is performed. It will result in much more disk and memory. Besides, complex data queries and data cleaning are not easy to be performed using MongoDB as lengthy scripting is required. Thus, MongoDB is only suitable for storage and simple data querying. For further pre-processing, other Hadoop tools should be used instead. HDFS is another alternative storage for these JSON files when pre-processing is required using other tools. First, the JSON data are loaded to HDFS storage. Then using Hadoop tools such as Apache Spark, Hive, and Pig, the JSON files can be loaded to the environment for further transformation as these tools have the built-in function to handle and read the JSON files. Both storage methods using MongoDB and HDFS will be discussed for demonstration.

## Automated Shell Scripts
1. BatchRun_Initial_Unzip.sh

Ubuntu application demonstrates the processes; however, the storage must be increased to 100GB due to the large data file size. The scripts for storing and accessing Yelp Data are available at the GitHub repository . Considering that the data are available in 5 different JSON files, each is downloaded separately and saved in a local file system. As stated earlier, the data files are available on 2 platforms: Yelp Dataset Official Page and Kaggle, maintained by Yelp's data team. To download the data from Yelp Dataset Official Page, public users must fill up personal particulars and agree to the License associated with the dataset. After that, users will be directed to the download site for the data. However, the download links generated are only available for 30 seconds.

Along with a pdf file about dataset usage agreement, the 5 JSON files are consolidated in tgz file with 4.9 GB. On the other hand, similar sets of JSON files are available at Kaggle, which can be downloaded separately in the zipped file. The downloaded files are unzipped before loading into the database. 
